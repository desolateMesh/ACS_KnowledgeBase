## Table of Contents
- [Overview](#overview)
- [Detection Prerequisites](#detection-prerequisites)
- [Containment Strategies](#containment-strategies)
- [Isolation Procedures](#isolation-procedures)
- [Network Segmentation](#network-segmentation)
- [Endpoint Containment](#endpoint-containment)
- [Cloud Containment](#cloud-containment)
- [Communication Protocols](#communication-protocols)
- [Tools and Technologies](#tools-and-technologies)
- [Automation and Orchestration](#automation-and-orchestration)
- [Post-Containment Actions](#post-containment-actions)
- [Metrics and KPIs](#metrics-and-kpis)
- [Lessons Learned](#lessons-learned)

## Overview

Malware containment is a critical phase in incident response that aims to prevent the spread of malicious software while maintaining business operations. This document provides comprehensive guidance for AI agents and security teams to make rapid, effective decisions during malware incidents.

### Key Objectives
- **Immediate Threat Isolation**: Prevent lateral movement of malware
- **Business Continuity**: Minimize disruption to critical operations
- **Evidence Preservation**: Maintain forensic integrity for investigation
- **Risk Mitigation**: Reduce potential data exfiltration and system damage

### Containment Philosophy
- **Speed over Perfection**: Act quickly with available information
- **Graduated Response**: Scale containment based on threat severity
- **Documentation**: Record all actions for post-incident analysis
- **Communication**: Maintain clear channels with all stakeholders

## Detection Prerequisites

Before initiating containment, ensure proper detection and assessment:

### Initial Detection Indicators
```yaml
detection_sources:
  - endpoint_detection_response:
      tools: [\"Microsoft Defender for Endpoint\", \"CrowdStrike\", \"SentinelOne\"]
      alerts:
        - suspicious_process_execution
        - unauthorized_file_modifications
        - anomalous_network_connections
  
  - network_monitoring:
      tools: [\"Azure Sentinel\", \"Splunk\", \"QRadar\"]
      indicators:
        - unusual_outbound_traffic
        - command_and_control_communications
        - data_exfiltration_patterns
  
  - user_behavior_analytics:
      tools: [\"Microsoft Defender for Identity\", \"Vectra AI\"]
      anomalies:
        - privilege_escalation_attempts
        - lateral_movement_patterns
        - credential_abuse
```

### Severity Assessment Matrix
```markdown
| Severity Level | Indicators | Containment Speed | Business Impact |
|----------------|------------|-------------------|-----------------|
| Critical | - Active ransomware encryption<br>- Domain controller compromise<br>- Mass data exfiltration | Immediate (< 15 mins) | Accept significant disruption |
| High | - Lateral movement detected<br>- Privileged account compromise<br>- C2 communication established | Rapid (< 1 hour) | Minimize critical service impact |
| Medium | - Single endpoint infection<br>- Suspicious but contained activity<br>- No lateral movement | Measured (< 4 hours) | Maintain normal operations |
| Low | - Potential false positive<br>- Historical infection<br>- Isolated suspicious file | Investigative (< 24 hours) | No disruption |
```

## Containment Strategies

### 1. Network-Based Containment

#### Firewall Rules Implementation
```python
# Example firewall rule automation
def implement_firewall_containment(infected_ips, threat_type):
    \"\"\"
    Implement emergency firewall rules for malware containment
    \"\"\"
    rules = {
        'ransomware': {
            'block_ports': [445, 139, 3389, 22],
            'block_protocols': ['SMB', 'RDP', 'SSH'],
            'direction': 'bidirectional'
        },
        'data_exfiltration': {
            'block_ports': [443, 80, 53, 8080],
            'block_protocols': ['HTTPS', 'HTTP', 'DNS'],
            'direction': 'outbound'
        },
        'lateral_movement': {
            'block_ports': [445, 139, 135, 3389],
            'block_protocols': ['SMB', 'RPC', 'RDP'],
            'direction': 'lateral'
        }
    }
    
    # Implementation logic
    for ip in infected_ips:
        if threat_type in rules:
            apply_rule(ip, rules[threat_type])
    
    return f\"Applied {threat_type} containment rules to {len(infected_ips)} hosts\"
```

#### VLAN Isolation
```yaml
vlan_isolation_procedure:
  steps:
    1_identify_affected_segments:
      - Map infected hosts to VLANs
      - Identify critical dependencies
      - Document current VLAN configuration
    
    2_create_isolation_vlan:
      - VLAN ID: 999 (Quarantine)
      - No routing enabled
      - Limited DHCP scope
      - Monitoring enabled
    
    3_move_infected_hosts:
      - Update switch port configurations
      - Maintain management access
      - Preserve forensic connectivity
    
    4_implement_acls:
      - Deny all except:
        - Management traffic (specific IPs)
        - Security tools communication
        - Forensic collection protocols
```

### 2. Host-Based Containment

#### Windows Endpoint Isolation
```powershell
# PowerShell script for Windows host isolation
function Invoke-HostIsolation {
    param(
        [string]$ComputerName,
        [string]$IsolationType,
        [bool]$PreserveForensics = $true
    )
    
    # Disable network adapters except management
    Get-NetAdapter -CimSession $ComputerName | 
        Where-Object {$_.Name -notmatch \"Management\"} | 
        Disable-NetAdapter -Confirm:$false
    
    # Block outbound connections via Windows Firewall
    Invoke-Command -ComputerName $ComputerName -ScriptBlock {
        New-NetFirewallRule -DisplayName \"Malware Containment Block\" `
            -Direction Outbound -Action Block -Enabled True `
            -Profile Domain,Private,Public
    }
    
    # Preserve forensic artifacts if requested
    if ($PreserveForensics) {
        # Create forensic preservation point
        Invoke-Command -ComputerName $ComputerName -ScriptBlock {
            $preservePath = \"C:\\ForensicPreserve\"
            New-Item -ItemType Directory -Path $preservePath -Force
            
            # Copy critical artifacts
            Copy-Item -Path \"$env:SystemRoot\\System32\\winevt\\Logs\\*\" `
                -Destination \"$preservePath\\EventLogs\" -Recurse
            Copy-Item -Path \"$env:SystemRoot\\Prefetch\\*\" `
                -Destination \"$preservePath\\Prefetch\" -Recurse
        }
    }
    
    return \"Host $ComputerName isolated with type: $IsolationType\"
}
```

#### Linux Endpoint Isolation
```bash
#!/bin/bash
# Linux host isolation script

isolate_linux_host() {
    local hostname=$1
    local isolation_level=$2
    
    # Implement iptables rules for isolation
    case $isolation_level in
        \"full\")
            # Block all traffic except SSH from management subnet
            iptables -P INPUT DROP
            iptables -P OUTPUT DROP
            iptables -P FORWARD DROP
            iptables -A INPUT -p tcp --dport 22 -s 10.0.1.0/24 -j ACCEPT
            iptables -A OUTPUT -p tcp --sport 22 -d 10.0.1.0/24 -j ACCEPT
            ;;
        \"partial\")
            # Block only suspicious ports and protocols
            iptables -A OUTPUT -p tcp --dport 443 -j DROP
            iptables -A OUTPUT -p tcp --dport 80 -j DROP
            iptables -A OUTPUT -p udp --dport 53 -j DROP
            ;;
        \"monitoring\")
            # Allow traffic but log everything
            iptables -A INPUT -j LOG --log-prefix \"MALWARE-IN: \"
            iptables -A OUTPUT -j LOG --log-prefix \"MALWARE-OUT: \"
            ;;
    esac
    
    # Preserve system state for forensics
    mkdir -p /forensics
    tar -czf /forensics/system_state_$(date +%Y%m%d_%H%M%S).tar.gz \\
        /var/log /etc /proc/[0-9]*/exe /proc/[0-9]*/cmdline
}
```

## Isolation Procedures

### Automated Isolation Workflow
```yaml
isolation_workflow:
  trigger:
    - severity: \"critical|high\"
    - confidence: \"> 75%\"
    - indicators: \"> 3\"
  
  phases:
    1_initial_response:
      duration: \"0-5 minutes\"
      actions:
        - Alert SOC team
        - Initiate automated containment
        - Begin evidence collection
      automation:
        - EDR auto-isolation
        - Network ACL updates
        - Snapshot creation
    
    2_assessment:
      duration: \"5-15 minutes\"
      actions:
        - Analyze threat scope
        - Identify patient zero
        - Map lateral movement
      tools:
        - SIEM correlation
        - Network traffic analysis
        - Endpoint telemetry
    
    3_expanded_containment:
      duration: \"15-60 minutes\"
      actions:
        - Isolate affected subnet
        - Implement firewall rules
        - Disable compromised accounts
      decisions:
        - Business impact assessment
        - Containment vs availability
        - Communication escalation
    
    4_stabilization:
      duration: \"1-4 hours\"
      actions:
        - Monitor for breakout
        - Validate containment
        - Plan remediation
      metrics:
        - No new infections
        - C2 traffic ceased
        - Data exfiltration stopped
```

### Manual Override Procedures
```markdown
## When to Override Automation

1. **False Positive Indicators**
   - Multiple business-critical systems affected
   - Known software deployment triggering alerts
   - Legitimate administrative activity

2. **Business Critical Operations**
   - End of quarter processing
   - Critical customer transactions
   - Life safety systems

3. **Special Circumstances**
   - Executive systems involved
   - Regulatory compliance requirements
   - Ongoing incident response

### Override Authorization Matrix
| System Type | Required Approval | Maximum Delay |
|-------------|------------------|---------------|
| Production Database | CISO + CTO | 30 minutes |
| Domain Controller | CISO + IT Director | 15 minutes |
| Executive Workstation | CISO + CEO | 1 hour |
| General Workstation | SOC Manager | 2 hours |
```

## Network Segmentation

### Microsegmentation Strategy
```yaml
microsegmentation_design:
  zones:
    dmz:
      description: \"Public-facing services\"
      containment_priority: \"immediate\"
      isolation_method: \"complete\"
      allowed_traffic:
        - source: \"internet\"
          destination: \"web_servers\"
          protocol: \"https\"
          port: 443
    
    internal_users:
      description: \"Standard user workstations\"
      containment_priority: \"high\"
      isolation_method: \"selective\"
      allowed_traffic:
        - source: \"workstations\"
          destination: \"domain_controllers\"
          protocol: \"kerberos\"
          port: 88
        - source: \"workstations\"
          destination: \"file_servers\"
          protocol: \"smb\"
          port: 445
    
    servers:
      description: \"Application and database servers\"
      containment_priority: \"critical\"
      isolation_method: \"granular\"
      allowed_traffic:
        - source: \"app_servers\"
          destination: \"database_servers\"
          protocol: \"mysql\"
          port: 3306
    
    management:
      description: \"Administrative access\"
      containment_priority: \"protected\"
      isolation_method: \"whitelist\"
      allowed_traffic:
        - source: \"jump_servers\"
          destination: \"all_zones\"
          protocol: \"ssh/rdp\"
          port: \"22/3389\"
```

### Zero Trust Implementation
```python
class ZeroTrustContainment:
    def __init__(self, threat_level):
        self.threat_level = threat_level
        self.trust_scores = {}
        self.containment_policies = {}
    
    def calculate_trust_score(self, entity):
        \"\"\"Calculate dynamic trust score for an entity\"\"\"
        factors = {
            'device_health': self.check_device_health(entity),
            'user_behavior': self.analyze_user_behavior(entity),
            'network_location': self.verify_network_location(entity),
            'time_of_access': self.check_access_time(entity),
            'authentication_strength': self.verify_auth_method(entity)
        }
        
        # Weighted scoring based on threat level
        weights = {
            'critical': {'device_health': 0.3, 'user_behavior': 0.3, 
                        'network_location': 0.2, 'time_of_access': 0.1,
                        'authentication_strength': 0.1},
            'high': {'device_health': 0.25, 'user_behavior': 0.25,
                    'network_location': 0.2, 'time_of_access': 0.15,
                    'authentication_strength': 0.15},
            'medium': {'device_health': 0.2, 'user_behavior': 0.2,
                      'network_location': 0.2, 'time_of_access': 0.2,
                      'authentication_strength': 0.2}
        }
        
        score = sum(factors[key] * weights[self.threat_level][key] 
                   for key in factors)
        return score
    
    def apply_containment_policy(self, entity, score):
        \"\"\"Apply containment based on trust score\"\"\"
        if score < 0.3:
            return self.full_isolation(entity)
        elif score < 0.6:
            return self.partial_isolation(entity)
        elif score < 0.8:
            return self.enhanced_monitoring(entity)
        else:
            return self.standard_monitoring(entity)
```

## Endpoint Containment

### Windows-Specific Containment
```powershell
# Comprehensive Windows containment script
function Start-WindowsMalwareContainment {
    [CmdletBinding()]
    param(
        [Parameter(Mandatory)]
        [string[]]$ComputerName,
        
        [Parameter(Mandatory)]
        [ValidateSet('Critical','High','Medium','Low')]
        [string]$ThreatLevel,
        
        [switch]$EnableForensics,
        [switch]$DisableUSB,
        [switch]$KillProcesses,
        [string[]]$ProcessNames
    )
    
    foreach ($Computer in $ComputerName) {
        try {
            # Create containment session
            $Session = New-PSSession -ComputerName $Computer -ErrorAction Stop
            
            # Execute containment based on threat level
            Invoke-Command -Session $Session -ScriptBlock {
                param($ThreatLevel, $EnableForensics, $DisableUSB, $KillProcesses, $ProcessNames)
                
                # Create containment log
                $LogPath = \"C:\\SecurityContainment\\$(Get-Date -Format 'yyyyMMdd_HHmmss')\"
                New-Item -Path $LogPath -ItemType Directory -Force
                
                # Disable Windows Defender real-time protection temporarily for forensics
                if ($EnableForensics) {
                    Set-MpPreference -DisableRealtimeMonitoring $true
                    
                    # Capture memory dump
                    $MemDumpPath = \"$LogPath\\memory.dmp\"
                    Start-Process -FilePath \"procdump.exe\" -ArgumentList \"-ma lsass.exe $MemDumpPath\" -Wait
                    
                    # Re-enable protection
                    Set-MpPreference -DisableRealtimeMonitoring $false
                }
                
                # Network isolation based on threat level
                switch ($ThreatLevel) {
                    'Critical' {
                        # Complete network isolation
                        Get-NetAdapter | Disable-NetAdapter -Confirm:$false
                        
                        # Disable all network services
                        Stop-Service -Name 'LanmanServer','LanmanWorkstation' -Force
                        Set-Service -Name 'LanmanServer','LanmanWorkstation' -StartupType Disabled
                    }
                    'High' {
                        # Selective network isolation
                        netsh advfirewall firewall add rule name=\"Containment_Block_Out\" `
                            dir=out action=block enable=yes
                        netsh advfirewall firewall add rule name=\"Containment_Allow_Mgmt\" `
                            dir=in action=allow protocol=TCP localport=5985 `
                            remoteip=10.0.1.0/24
                    }
                    'Medium' {
                        # Block suspicious ports only
                        $SuspiciousPorts = @(445, 139, 3389, 22, 23, 21, 443, 80)
                        foreach ($Port in $SuspiciousPorts) {
                            netsh advfirewall firewall add rule `
                                name=\"Containment_Block_Port_$Port\" `
                                dir=out action=block protocol=TCP remoteport=$Port
                        }
                    }
                    'Low' {
                        # Monitoring mode only
                        netsh advfirewall set allprofiles logging enable
                        netsh advfirewall set allprofiles logging maxfilesize 32767
                    }
                }
                
                # Kill malicious processes if specified
                if ($KillProcesses -and $ProcessNames) {
                    foreach ($Process in $ProcessNames) {
                        Get-Process -Name $Process -ErrorAction SilentlyContinue | 
                            Stop-Process -Force
                    }
                }
                
                # Disable USB if requested
                if ($DisableUSB) {
                    $USBStorageKey = 'HKLM:\\SYSTEM\\CurrentControlSet\\Services\\USBSTOR'
                    Set-ItemProperty -Path $USBStorageKey -Name Start -Value 4
                }
                
                # Create containment report
                $Report = @{
                    ComputerName = $env:COMPUTERNAME
                    ContainmentTime = Get-Date
                    ThreatLevel = $ThreatLevel
                    ActionsPerformed = @{
                        NetworkIsolation = $true
                        USBDisabled = $DisableUSB
                        ProcessesKilled = $ProcessNames -join ', '
                        ForensicsEnabled = $EnableForensics
                    }
                }
                
                $Report | ConvertTo-Json | Out-File \"$LogPath\\containment_report.json\"
                
                return $Report
            } -ArgumentList $ThreatLevel, $EnableForensics, $DisableUSB, $KillProcesses, $ProcessNames
            
            Remove-PSSession -Session $Session
        }
        catch {
            Write-Error \"Failed to contain $Computer : $_\"
        }
    }
}
```

### macOS Containment
```bash
#!/bin/bash
# macOS malware containment script

perform_macos_containment() {
    local threat_level=$1
    local system_id=$2
    
    # Create forensics directory
    forensics_dir=\"/var/containment/$(date +%Y%m%d_%H%M%S)\"
    mkdir -p \"$forensics_dir\"
    
    # Capture system state
    system_profiler SPHardwareDataType SPSoftwareDataType > \"$forensics_dir/system_profile.txt\"
    ps aux > \"$forensics_dir/processes.txt\"
    netstat -an > \"$forensics_dir/network_connections.txt\"
    
    case $threat_level in
        \"critical\")
            # Disable all network interfaces
            networksetup -listallnetworkservices | grep -v \"An asterisk\" | while read service; do
                networksetup -setv6off \"$service\"
                networksetup -setv4off \"$service\" 
            done
            
            # Kill suspicious processes
            sudo killall -9 suspicious_process_name
            
            # Disable launch daemons/agents
            launchctl bootout system/com.suspicious.daemon
            ;;
            
        \"high\")
            # Block outbound connections with pfctl
            echo \"block out all\" > /tmp/malware_containment.conf
            echo \"pass in proto tcp from 10.0.1.0/24 to any port 22\" >> /tmp/malware_containment.conf
            pfctl -ef /tmp/malware_containment.conf
            ;;
            
        \"medium\")
            # Enable firewall with strict rules
            /usr/libexec/ApplicationFirewall/socketfilterfw --setglobalstate on
            /usr/libexec/ApplicationFirewall/socketfilterfw --setblockall on
            ;;
    esac
    
    # Create containment report
    cat > \"$forensics_dir/containment_report.json\" <<EOF
{
    \"system_id\": \"$system_id\",
    \"threat_level\": \"$threat_level\",
    \"containment_time\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",
    \"actions_taken\": \"Network isolation, process termination, firewall activation\"
}
EOF
}
```

### Linux Advanced Containment
```python
#!/usr/bin/env python3
import subprocess
import os
import json
import datetime
import shutil

class LinuxMalwareContainment:
    def __init__(self, threat_level, system_id):
        self.threat_level = threat_level
        self.system_id = system_id
        self.containment_log = []
        self.forensics_path = f\"/var/containment/{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"
        
    def initialize_containment(self):
        \"\"\"Initialize containment environment\"\"\"
        os.makedirs(self.forensics_path, exist_ok=True)
        self.log_action(\"Initialized containment environment\")
        
    def capture_system_state(self):
        \"\"\"Capture current system state for forensics\"\"\"
        commands = {
            'processes': 'ps auxww',
            'network_connections': 'netstat -tulpn',
            'open_files': 'lsof -n',
            'system_info': 'uname -a',
            'loaded_modules': 'lsmod',
            'iptables_rules': 'iptables -L -n -v',
            'services': 'systemctl list-units --type=service --state=running'
        }
        
        for name, cmd in commands.items():
            try:
                output = subprocess.check_output(cmd, shell=True, text=True)
                with open(f\"{self.forensics_path}/{name}.txt\", 'w') as f:
                    f.write(output)
                self.log_action(f\"Captured {name}\")
            except Exception as e:
                self.log_action(f\"Failed to capture {name}: {str(e)}\")
                
    def implement_network_containment(self):
        \"\"\"Implement network-level containment\"\"\"
        if self.threat_level == 'critical':
            # Complete network isolation
            rules = [
                'iptables -P INPUT DROP',
                'iptables -P FORWARD DROP', 
                'iptables -P OUTPUT DROP',
                # Allow only management SSH
                'iptables -A INPUT -p tcp --dport 22 -s 10.0.1.0/24 -j ACCEPT',
                'iptables -A OUTPUT -p tcp --sport 22 -d 10.0.1.0/24 -j ACCEPT'
            ]
        elif self.threat_level == 'high':
            # Selective blocking
            rules = [
                # Block common malware ports
                'iptables -A OUTPUT -p tcp --dport 445 -j DROP',  # SMB
                'iptables -A OUTPUT -p tcp --dport 139 -j DROP',  # NetBIOS
                'iptables -A OUTPUT -p tcp --dport 3389 -j DROP', # RDP
                # Block DNS except to internal servers
                'iptables -A OUTPUT -p udp --dport 53 ! -d 10.0.1.0/24 -j DROP',
                # Log all connections
                'iptables -A INPUT -j LOG --log-prefix \"MALWARE-IN: \"',
                'iptables -A OUTPUT -j LOG --log-prefix \"MALWARE-OUT: \"'
            ]
        else:
            # Monitoring mode
            rules = [
                'iptables -A INPUT -j LOG --log-prefix \"MONITOR-IN: \"',
                'iptables -A OUTPUT -j LOG --log-prefix \"MONITOR-OUT: \"'
            ]
            
        for rule in rules:
            try:
                subprocess.run(rule, shell=True, check=True)
                self.log_action(f\"Applied rule: {rule}\")
            except Exception as e:
                self.log_action(f\"Failed to apply rule {rule}: {str(e)}\")
                
    def contain_processes(self):
        \"\"\"Identify and contain malicious processes\"\"\"
        suspicious_patterns = [
            'cryptominer', 'ransomware', 'backdoor', 'rootkit',
            'reverse_shell', 'meterpreter', 'cobalt_strike'
        ]
        
        # Get process list
        try:
            ps_output = subprocess.check_output(\"ps aux\", shell=True, text=True)
            
            for line in ps_output.split('\
')[1:]:  # Skip header
                if any(pattern in line.lower() for pattern in suspicious_patterns):
                    parts = line.split()
                    if len(parts) > 1:
                        pid = parts[1]
                        process_name = ' '.join(parts[10:])
                        
                        # Kill suspicious process
                        try:
                            subprocess.run(f\"kill -9 {pid}\", shell=True, check=True)
                            self.log_action(f\"Killed suspicious process: {process_name} (PID: {pid})\")
                        except:
                            self.log_action(f\"Failed to kill process {pid}\")
                            
                        # Capture process memory if possible
                        self.capture_process_memory(pid)
        except Exception as e:
            self.log_action(f\"Process containment error: {str(e)}\")
            
    def contain_filesystem(self):
        \"\"\"Implement filesystem-level containment\"\"\"
        # Remount critical filesystems as read-only
        critical_mounts = ['/boot', '/usr', '/opt']
        
        for mount in critical_mounts:
            try:
                subprocess.run(f\"mount -o remount,ro {mount}\", shell=True, check=True)
                self.log_action(f\"Remounted {mount} as read-only\")
            except:
                self.log_action(f\"Failed to remount {mount}\")
                
        # Set immutable bit on critical files
        critical_files = [
            '/etc/passwd', '/etc/shadow', '/etc/group',
            '/etc/sudoers', '/etc/ssh/sshd_config'
        ]
        
        for file in critical_files:
            try:
                subprocess.run(f\"chattr +i {file}\", shell=True, check=True)
                self.log_action(f\"Set immutable flag on {file}\")
            except:
                self.log_action(f\"Failed to protect {file}\")
                
    def implement_selinux_containment(self):
        \"\"\"Use SELinux for additional containment\"\"\"
        try:
            # Set SELinux to enforcing mode
            subprocess.run(\"setenforce 1\", shell=True, check=True)
            self.log_action(\"Set SELinux to enforcing mode\")
            
            # Apply custom SELinux context for suspicious files
            suspicious_dirs = ['/tmp', '/var/tmp', '/dev/shm']
            for dir in suspicious_dirs:
                subprocess.run(f\"chcon -R -t unlabeled_t {dir}\", shell=True)
                self.log_action(f\"Applied restrictive SELinux context to {dir}\")
        except:
            self.log_action(\"SELinux containment not available\")
            
    def create_containment_report(self):
        \"\"\"Generate comprehensive containment report\"\"\"
        report = {
            'system_id': self.system_id,
            'threat_level': self.threat_level,
            'containment_start': self.containment_log[0]['timestamp'] if self.containment_log else None,
            'containment_end': datetime.datetime.now().isoformat(),
            'actions_performed': self.containment_log,
            'forensics_location': self.forensics_path,
            'recommendations': self.generate_recommendations()
        }
        
        with open(f\"{self.forensics_path}/containment_report.json\", 'w') as f:
            json.dump(report, f, indent=2)
            
        return report
        
    def generate_recommendations(self):
        \"\"\"Generate post-containment recommendations\"\"\"
        recommendations = []
        
        if self.threat_level in ['critical', 'high']:
            recommendations.extend([
                \"Perform full system reimaging after forensic collection\",
                \"Reset all user credentials on affected system\",
                \"Review and update security policies\",
                \"Conduct threat hunting on similar systems\"
            ])
        else:
            recommendations.extend([
                \"Continue monitoring for 72 hours\",
                \"Perform vulnerability scan\",
                \"Update system patches\",
                \"Review security logs for indicators\"
            ])
            
        return recommendations
        
    def log_action(self, action):
        \"\"\"Log containment actions\"\"\"
        entry = {
            'timestamp': datetime.datetime.now().isoformat(),
            'action': action
        }
        self.containment_log.append(entry)
        print(f\"[{entry['timestamp']}] {action}\")
        
    def execute_containment(self):
        \"\"\"Execute complete containment workflow\"\"\"
        self.initialize_containment()
        self.capture_system_state()
        self.implement_network_containment()
        self.contain_processes()
        self.contain_filesystem()
        self.implement_selinux_containment()
        report = self.create_containment_report()
        
        return report

# Usage example
if __name__ == \"__main__\":
    import sys
    
    if len(sys.argv) != 3:
        print(\"Usage: linux_containment.py <threat_level> <system_id>\")
        sys.exit(1)
        
    threat_level = sys.argv[1]
    system_id = sys.argv[2]
    
    containment = LinuxMalwareContainment(threat_level, system_id)
    report = containment.execute_containment()
    
    print(\"\
Containment Complete. Report saved to:\", report['forensics_location'])
```

## Cloud Containment

### Azure-Specific Containment
```yaml
azure_containment_procedures:
  vm_isolation:
    steps:
      - identify_infected_vms:
          query: |
            SecurityEvent
            | where EventID == 4688
            | where Process contains \"suspicious\"
            | distinct Computer
            
      - network_isolation:
          actions:
            - Create NSG rule to block all traffic
            - Apply NSG to infected VM NIC
            - Remove VM from load balancer pools
          
      - snapshot_creation:
          command: |
            az vm create-snapshot \\
              --resource-group <rg> \\
              --name <vm>-forensic \\
              --source <vm-disk>
              
      - access_control:
          - Revoke all RBAC permissions
          - Apply resource lock
          - Enable JIT access only
          
  storage_containment:
    blob_storage:
      - Enable immutability policy
      - Block public access
      - Rotate storage account keys
      - Enable logging and monitoring
      
    key_vault:
      - Enable soft delete
      - Implement firewall rules
      - Rotate all secrets
      - Review access policies
      
  identity_protection:
    steps:
      - Disable compromised accounts
      - Reset MFA for all users
      - Review conditional access
      - Enable risk-based policies
```

### AWS Containment
```python
import boto3
import json
from datetime import datetime

class AWSMalwareContainment:
    def __init__(self, region='us-east-1'):
        self.ec2 = boto3.client('ec2', region_name=region)
        self.iam = boto3.client('iam')
        self.s3 = boto3.client('s3')
        self.session = boto3.Session()
        self.region = region
        
    def isolate_ec2_instance(self, instance_id):
        \"\"\"Isolate an EC2 instance\"\"\"
        
        # Create isolation security group
        isolation_sg = self.create_isolation_security_group()
        
        # Get current instance details
        instance = self.ec2.describe_instances(
            InstanceIds=[instance_id]
        )['Reservations'][0]['Instances'][0]
        
        # Create snapshot for forensics
        self.create_forensic_snapshot(instance_id)
        
        # Apply isolation security group
        self.ec2.modify_instance_attribute(
            InstanceId=instance_id,
            Groups=[isolation_sg]
        )
        
        # Remove from Auto Scaling groups if applicable
        self.remove_from_auto_scaling(instance_id)
        
        # Tag instance as contained
        self.ec2.create_tags(
            Resources=[instance_id],
            Tags=[
                {
                    'Key': 'MalwareContainment',
                    'Value': f'Isolated-{datetime.now().isoformat()}'
                }
            ]
        )
        
        return {
            'instance_id': instance_id,
            'isolation_sg': isolation_sg,
            'status': 'isolated'
        }
        
    def create_isolation_security_group(self):
        \"\"\"Create a security group that blocks all traffic\"\"\"
        
        sg_name = f'malware-isolation-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'
        
        response = self.ec2.create_security_group(
            GroupName=sg_name,
            Description='Malware containment isolation group'
        )
        
        sg_id = response['GroupId']
        
        # Remove all inbound rules (default allows none)
        # Remove default outbound rule
        self.ec2.revoke_security_group_egress(
            GroupId=sg_id,
            IpPermissions=[{
                'IpProtocol': '-1',
                'FromPort': -1,
                'ToPort': -1,
                'IpRanges': [{'CidrIp': '0.0.0.0/0'}]
            }]
        )
        
        # Add only management access if needed
        self.ec2.authorize_security_group_ingress(
            GroupId=sg_id,
            IpPermissions=[{
                'IpProtocol': 'tcp',
                'FromPort': 22,
                'ToPort': 22,
                'IpRanges': [{'CidrIp': '10.0.1.0/24'}]  # Management subnet
            }]
        )
        
        return sg_id
        
    def isolate_iam_user(self, user_name):
        \"\"\"Contain a potentially compromised IAM user\"\"\"
        
        # Attach deny-all policy
        deny_policy = {
            \"Version\": \"2012-10-17\",
            \"Statement\": [{
                \"Effect\": \"Deny\",
                \"Action\": \"*\",
                \"Resource\": \"*\"
            }]
        }
        
        policy_name = f'MalwareContainment-{user_name}-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'
        
        self.iam.put_user_policy(
            UserName=user_name,
            PolicyName=policy_name,
            PolicyDocument=json.dumps(deny_policy)
        )
        
        # Deactivate access keys
        response = self.iam.list_access_keys(UserName=user_name)
        for key in response['AccessKeyMetadata']:
            self.iam.update_access_key(
                UserName=user_name,
                AccessKeyId=key['AccessKeyId'],
                Status='Inactive'
            )
            
        # Remove from groups
        groups = self.iam.list_groups_for_user(UserName=user_name)
        for group in groups['Groups']:
            self.iam.remove_user_from_group(
                GroupName=group['GroupName'],
                UserName=user_name
            )
            
        return {
            'user': user_name,
            'status': 'contained',
            'policy_attached': policy_name
        }
        
    def isolate_s3_bucket(self, bucket_name):
        \"\"\"Contain a potentially compromised S3 bucket\"\"\"
        
        # Block all public access
        self.s3.put_public_access_block(
            Bucket=bucket_name,
            PublicAccessBlockConfiguration={
                'BlockPublicAcls': True,
                'IgnorePublicAcls': True,
                'BlockPublicPolicy': True,
                'RestrictPublicBuckets': True
            }
        )
        
        # Apply bucket policy to deny all access except forensics
        bucket_policy = {
            \"Version\": \"2012-10-17\",
            \"Statement\": [
                {
                    \"Sid\": \"DenyAllExceptForensics\",
                    \"Effect\": \"Deny\",
                    \"Principal\": \"*\",
                    \"Action\": \"s3:*\",
                    \"Resource\": [
                        f\"arn:aws:s3:::{bucket_name}\",
                        f\"arn:aws:s3:::{bucket_name}/*\"
                    ],
                    \"Condition\": {
                        \"StringNotEquals\": {
                            \"aws:userid\": \"AIDAI23HRB2C4EXAMPLE\"  # Forensics role
                        }
                    }
                }
            ]
        }
        
        self.s3.put_bucket_policy(
            Bucket=bucket_name,
            Policy=json.dumps(bucket_policy)
        )
        
        # Enable versioning to preserve evidence
        self.s3.put_bucket_versioning(
            Bucket=bucket_name,
            VersioningConfiguration={'Status': 'Enabled'}
        )
        
        # Enable logging
        self.s3.put_bucket_logging(
            Bucket=bucket_name,
            BucketLoggingStatus={
                'LoggingEnabled': {
                    'TargetBucket': 'security-logs-bucket',
                    'TargetPrefix': f'malware-containment/{bucket_name}/'
                }
            }
        )
        
        return {
            'bucket': bucket_name,
            'status': 'contained',
            'versioning': 'enabled',
            'logging': 'enabled'
        }
```

### Kubernetes Containment
```yaml
kubernetes_containment:
  pod_isolation:
    network_policy: |
      apiVersion: networking.k8s.io/v1
      kind: NetworkPolicy
      metadata:
        name: malware-containment-isolation
        namespace: infected-namespace
      spec:
        podSelector:
          matchLabels:
            quarantine: \"true\"
        policyTypes:
        - Ingress
        - Egress
        ingress:
        - from:
          - namespaceSelector:
              matchLabels:
                name: security-tools
          ports:
          - protocol: TCP
            port: 22
        egress:
        - to:
          - namespaceSelector:
              matchLabels:
                name: security-logging
          ports:
          - protocol: TCP
            port: 514
            
  node_isolation:
    script: |
      #!/bin/bash
      # Cordon and drain infected node
      kubectl cordon $NODE_NAME
      kubectl drain $NODE_NAME --ignore-daemonsets --delete-local-data
      
      # Apply taint to prevent scheduling
      kubectl taint nodes $NODE_NAME malware=infected:NoSchedule
      
      # Label for identification
      kubectl label nodes $NODE_NAME containment=active
      
  namespace_quarantine:
    steps:
      - Apply resource quota to limit damage
      - Implement network policies
      - Disable service accounts
      - Block ingress traffic
      - Capture pod logs and states
```

## Communication Protocols

### Incident Communication Matrix
```yaml
communication_matrix:
  stakeholders:
    technical_team:
      primary_contact: \"soc@company.com\"
      escalation: \"security-leadership@company.com\"
      communication_method: [\"slack\", \"email\", \"phone\"]
      update_frequency: \"15 minutes\"
      
    executive_team:
      primary_contact: \"ciso@company.com\"
      escalation: \"ceo@company.com\"
      communication_method: [\"phone\", \"secure_email\"]
      update_frequency: \"hourly\"
      
    legal_team:
      primary_contact: \"legal@company.com\"
      escalation: \"general-counsel@company.com\"
      communication_method: [\"secure_email\", \"phone\"]
      update_frequency: \"as_needed\"
      
    external_partners:
      primary_contact: \"vendor-security@partner.com\"
      escalation: \"ciso@partner.com\"
      communication_method: [\"secure_portal\", \"phone\"]
      update_frequency: \"daily\"
      
  templates:
    initial_notification: |
      Subject: [SECURITY INCIDENT] Malware Detection - {severity}
      
      Incident Type: Malware Detection
      Severity: {severity}
      Detection Time: {detection_time}
      Affected Systems: {affected_count}
      
      Initial Assessment:
      - Threat Type: {threat_type}
      - Spread Status: {spread_status}
      - Business Impact: {business_impact}
      
      Actions Taken:
      - Automated containment initiated
      - Manual review in progress
      - Forensics collection started
      
      Next Steps:
      - Complete containment validation
      - Begin eradication planning
      - Prepare detailed report
      
    status_update: |
      Subject: [UPDATE] Malware Incident - {incident_id}
      
      Status: {current_status}
      Time Since Detection: {elapsed_time}
      
      Progress Update:
      - Containment: {containment_percentage}% complete
      - Systems Isolated: {isolated_count}
      - Data Preserved: {forensics_status}
      
      Challenges:
      {challenges_list}
      
      Estimated Resolution: {eta}
      
    final_report: |
      Subject: [CLOSED] Malware Incident Report - {incident_id}
      
      Executive Summary:
      {executive_summary}
      
      Timeline:
      - Detection: {detection_time}
      - Containment: {containment_time}
      - Eradication: {eradication_time}
      - Recovery: {recovery_time}
      
      Impact Assessment:
      - Systems Affected: {systems_count}
      - Data Exposure: {data_status}
      - Business Impact: {business_impact}
      - Financial Impact: {financial_impact}
      
      Root Cause:
      {root_cause_analysis}
      
      Lessons Learned:
      {lessons_learned}
      
      Recommendations:
      {recommendations}
```

### Real-time Status Dashboard
```python
from flask import Flask, jsonify, render_template
import threading
import time
from datetime import datetime

class ContainmentDashboard:
    def __init__(self):
        self.app = Flask(__name__)
        self.status_data = {
            'incident_id': None,
            'start_time': None,
            'current_phase': 'detection',
            'affected_systems': [],
            'contained_systems': [],
            'metrics': {
                'containment_progress': 0,
                'systems_at_risk': 0,
                'data_protected': True,
                'network_isolated': False
            },
            'timeline': []
        }
        self.setup_routes()
        
    def setup_routes(self):
        @self.app.route('/api/status')
        def get_status():
            return jsonify(self.status_data)
            
        @self.app.route('/api/metrics')
        def get_metrics():
            return jsonify(self.calculate_metrics())
            
        @self.app.route('/api/timeline')
        def get_timeline():
            return jsonify(self.status_data['timeline'])
            
        @self.app.route('/')
        def dashboard():
            return render_template('containment_dashboard.html')
            
    def update_status(self, update_type, data):
        \"\"\"Update dashboard status\"\"\"
        timestamp = datetime.now().isoformat()
        
        if update_type == 'system_contained':
            self.status_data['contained_systems'].append(data['system_id'])
            self.status_data['metrics']['containment_progress'] = (
                len(self.status_data['contained_systems']) / 
                len(self.status_data['affected_systems']) * 100
            )
            
        elif update_type == 'phase_change':
            self.status_data['current_phase'] = data['new_phase']
            
        elif update_type == 'metric_update':
            self.status_data['metrics'].update(data)
            
        # Add to timeline
        self.status_data['timeline'].append({
            'timestamp': timestamp,
            'type': update_type,
            'data': data
        })
        
    def calculate_metrics(self):
        \"\"\"Calculate real-time metrics\"\"\"
        metrics = {
            'containment_velocity': self.calculate_containment_velocity(),
            'risk_score': self.calculate_risk_score(),
            'estimated_completion': self.estimate_completion_time(),
            'resource_utilization': self.get_resource_utilization()
        }
        return metrics
        
    def calculate_containment_velocity(self):
        \"\"\"Calculate rate of containment\"\"\"
        if len(self.status_data['timeline']) < 2:
            return 0
            
        contained_events = [
            e for e in self.status_data['timeline'] 
            if e['type'] == 'system_contained'
        ]
        
        if len(contained_events) < 2:
            return 0
            
        time_diff = (
            datetime.fromisoformat(contained_events[-1]['timestamp']) -
            datetime.fromisoformat(contained_events[0]['timestamp'])
        ).total_seconds() / 60  # minutes
        
        systems_per_minute = len(contained_events) / time_diff
        return round(systems_per_minute, 2)
        
    def calculate_risk_score(self):
        \"\"\"Calculate current risk score\"\"\"
        factors = {
            'uncontained_systems': len(self.status_data['affected_systems']) - 
                                 len(self.status_data['contained_systems']),
            'lateral_movement': self.status_data['metrics'].get('lateral_movement_detected', False),
            'data_exfiltration': self.status_data['metrics'].get('data_exfiltration_detected', False),
            'time_elapsed': (datetime.now() - 
                           datetime.fromisoformat(self.status_data['start_time'])).total_seconds() / 3600
        }
        
        risk_score = (
            factors['uncontained_systems'] * 10 +
            (50 if factors['lateral_movement'] else 0) +
            (100 if factors['data_exfiltration'] else 0) +
            factors['time_elapsed'] * 5
        )
        
        return min(100, risk_score)  # Cap at 100
        
    def estimate_completion_time(self):
        \"\"\"Estimate time to complete containment\"\"\"
        velocity = self.calculate_containment_velocity()
        if velocity == 0:
            return \"Unable to estimate\"
            
        remaining_systems = (
            len(self.status_data['affected_systems']) - 
            len(self.status_data['contained_systems'])
        )
        
        minutes_remaining = remaining_systems / velocity
        completion_time = datetime.now() + datetime.timedelta(minutes=minutes_remaining)
        
        return completion_time.isoformat()
        
    def get_resource_utilization(self):
        \"\"\"Get current resource utilization\"\"\"
        # This would integrate with monitoring systems
        return {
            'cpu_usage': 75,  # Placeholder
            'memory_usage': 82,  # Placeholder
            'network_bandwidth': 45,  # Placeholder
            'disk_io': 60  # Placeholder
        }
        
    def run(self, host='0.0.0.0', port=5000):
        \"\"\"Run the dashboard server\"\"\"
        self.app.run(host=host, port=port, debug=False)

# HTML Template (containment_dashboard.html)
dashboard_html = \"\"\"
<!DOCTYPE html>
<html>
<head>
    <title>Malware Containment Dashboard</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .metric { 
            display: inline-block; 
            margin: 10px; 
            padding: 15px; 
            border: 1px solid #ccc; 
            border-radius: 5px; 
        }
        .critical { background-color: #ffcccc; }
        .warning { background-color: #ffffcc; }
        .normal { background-color: #ccffcc; }
        #timeline { 
            height: 300px; 
            overflow-y: scroll; 
            border: 1px solid #ccc; 
            padding: 10px; 
        }
    </style>
    <script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>
</head>
<body>
    <h1>Malware Containment Dashboard</h1>
    
    <div id=\"status-summary\">
        <h2>Current Status</h2>
        <div class=\"metric\">
            <h3>Phase</h3>
            <p id=\"current-phase\">Loading...</p>
        </div>
        <div class=\"metric\">
            <h3>Containment Progress</h3>
            <p id=\"containment-progress\">0%</p>
        </div>
        <div class=\"metric\">
            <h3>Risk Score</h3>
            <p id=\"risk-score\">0</p>
        </div>
    </div>
    
    <div id=\"metrics\">
        <h2>Real-time Metrics</h2>
        <div class=\"metric\">
            <h3>Containment Velocity</h3>
            <p id=\"containment-velocity\">0 systems/min</p>
        </div>
        <div class=\"metric\">
            <h3>Estimated Completion</h3>
            <p id=\"estimated-completion\">Calculating...</p>
        </div>
    </div>
    
    <div id=\"timeline-container\">
        <h2>Event Timeline</h2>
        <div id=\"timeline\"></div>
    </div>
    
    <script>
        function updateDashboard() {
            // Update status
            $.get('/api/status', function(data) {
                $('#current-phase').text(data.current_phase);
                $('#containment-progress').text(data.metrics.containment_progress + '%');
                
                // Update progress bar color based on progress
                var progress = data.metrics.containment_progress;
                var progressClass = progress < 30 ? 'critical' : 
                                   progress < 70 ? 'warning' : 'normal';
                $('#containment-progress').parent().attr('class', 'metric ' + progressClass);
            });
            
            // Update metrics
            $.get('/api/metrics', function(data) {
                $('#containment-velocity').text(data.containment_velocity + ' systems/min');
                $('#risk-score').text(data.risk_score);
                $('#estimated-completion').text(new Date(data.estimated_completion).toLocaleString());
                
                // Update risk score color
                var risk = data.risk_score;
                var riskClass = risk > 70 ? 'critical' : 
                               risk > 30 ? 'warning' : 'normal';
                $('#risk-score').parent().attr('class', 'metric ' + riskClass);
            });
            
            // Update timeline
            $.get('/api/timeline', function(data) {
                var timeline = $('#timeline');
                timeline.empty();
                
                data.reverse().forEach(function(event) {
                    var eventHtml = '<div class=\"timeline-event\">' +
                        '<strong>' + new Date(event.timestamp).toLocaleString() + '</strong>: ' +
                        event.type + ' - ' + JSON.stringify(event.data) +
                        '</div>';
                    timeline.append(eventHtml);
                });
            });
        }
        
        // Update dashboard every 5 seconds
        setInterval(updateDashboard, 5000);
        updateDashboard(); // Initial load
    </script>
</body>
</html>
\"\"\"
```

## Tools and Technologies

### EDR Integration
```yaml
edr_tools:
  microsoft_defender:
    capabilities:
      - automated_isolation
      - process_termination
      - file_quarantine
      - network_blocking
    api_endpoints:
      isolate_machine: \"POST /api/machines/{id}/isolate\"
      release_machine: \"POST /api/machines/{id}/release\"
      restrict_app: \"POST /api/machines/{id}/restrictAppExecution\"
    integration_example: |
      # PowerShell integration
      $MachineId = \"machine-guid\"
      $IsolationType = \"Full\"
      
      Invoke-WebRequest -Uri \"https://api.securitycenter.microsoft.com/api/machines/$MachineId/isolate\" `
        -Method Post `
        -Headers @{Authorization = \"Bearer $Token\"} `
        -Body (@{
          Comment = \"Malware containment - automated response\"
          IsolationType = $IsolationType
        } | ConvertTo-Json)
        
  crowdstrike:
    capabilities:
      - network_containment
      - kill_process
      - delete_file
      - memory_dump
    api_endpoints:
      contain_host: \"POST /devices/entities/devices-actions/v2\"
      lift_containment: \"POST /devices/entities/devices-actions/v2\"
    integration_example: |
      # Python integration
      import requests
      
      def contain_crowdstrike_host(host_id, token):
          url = \"https://api.crowdstrike.com/devices/entities/devices-actions/v2\"
          headers = {
              \"Authorization\": f\"Bearer {token}\",
              \"Content-Type\": \"application/json\"
          }
          data = {
              \"ids\": [host_id],
              \"action_name\": \"contain\"
          }
          response = requests.post(url, headers=headers, json=data)
          return response.json()
          
  sentinelone:
    capabilities:
      - network_quarantine
      - process_blacklisting
      - rollback_capability
      - threat_mitigation
    api_endpoints:
      isolate_endpoint: \"POST /web/api/v2.1/agents/actions/isolate\"
      kill_threat: \"POST /web/api/v2.1/threats/{threat_id}/kill\"
```

### SIEM Orchestration
```python
class SIEMOrchestrator:
    def __init__(self, siem_type):
        self.siem_type = siem_type
        self.connection = self.establish_connection()
        
    def establish_connection(self):
        \"\"\"Establish connection to SIEM\"\"\"
        connections = {
            'splunk': self.connect_splunk,
            'qradar': self.connect_qradar,
            'sentinel': self.connect_sentinel
        }
        return connections.get(self.siem_type)()
        
    def connect_splunk(self):
        \"\"\"Connect to Splunk\"\"\"
        import splunklib.client as client
        return client.connect(
            host='splunk.company.com',
            port=8089,
            username='siem_automation',
            password='secure_password'
        )
        
    def create_containment_query(self, ioc_type, ioc_value):
        \"\"\"Create SIEM query for containment\"\"\"
        queries = {
            'splunk': {
                'ip': f'search index=* src_ip={ioc_value} OR dest_ip={ioc_value} | table _time src_ip dest_ip action',
                'hash': f'search index=* file_hash={ioc_value} | table _time host file_name file_hash',
                'domain': f'search index=* dest_host={ioc_value} | table _time src_ip dest_host bytes_out'
            },
            'qradar': {
                'ip': f'SELECT * FROM events WHERE sourceip=\\'{ioc_value}\\' OR destinationip=\\'{ioc_value}\\'',
                'hash': f'SELECT * FROM events WHERE filehash=\\'{ioc_value}\\'',
                'domain': f'SELECT * FROM events WHERE domainname=\\'{ioc_value}\\''
            }
        }
        return queries[self.siem_type][ioc_type]
        
    def get_affected_systems(self, ioc_type, ioc_value):
        \"\"\"Query SIEM for affected systems\"\"\"
        query = self.create_containment_query(ioc_type, ioc_value)
        
        if self.siem_type == 'splunk':
            job = self.connection.jobs.create(query, **{\"exec_mode\": \"oneshot\"})
            results = []
            for result in job.results():
                results.append(result)
            return results
            
        # Add other SIEM implementations
        
    def create_containment_alert(self, systems, threat_info):
        \"\"\"Create alert in SIEM for containment tracking\"\"\"
        alert_data = {
            'title': f'Malware Containment - {threat_info[\"type\"]}',
            'description': f'Automated containment initiated for {len(systems)} systems',
            'severity': threat_info['severity'],
            'affected_systems': systems,
            'containment_actions': threat_info['actions']
        }
        
        if self.siem_type == 'splunk':
            # Create notable event
            self.connection.notable_event.create(**alert_data)
            
        return alert_data
        
    def monitor_containment_effectiveness(self, ioc_value, baseline_time):
        \"\"\"Monitor if containment is effective\"\"\"
        monitoring_query = f\"\"\"
        search index=* {ioc_value} earliest={baseline_time}
        | timechart span=5m count by action
        | where count > 0
        \"\"\"
        
        job = self.connection.jobs.create(monitoring_query)
        
        # Check if malicious activity continues
        for result in job.results():
            if int(result['count']) > 0:
                return False, \"Malicious activity still detected\"
                
        return True, \"Containment appears effective\"
```

### Forensics Tools Integration
```yaml
forensics_integration:
  velociraptor:
    deployment:
      - Push agent to infected system
      - Execute artifact collection
      - Stream results to central server
    artifacts:
      - Windows.System.ProcessList
      - Windows.Memory.ProcessInfo
      - Windows.Network.NetstatEnriched
      - Windows.Registry.RecentDocs
      - Windows.EventLogs.Security
    integration_script: |
      # Velociraptor collection script
      flows:
        - name: MalwareContainmentCollection
          artifacts:
            - Windows.Detection.MaliciousFiles
            - Windows.Memory.AquisitionWinPMem
            - Windows.Network.PacketCapture
          parameters:
            Windows.Memory.AquisitionWinPMem:
              VelociraptorTempDir: C:\\Temp\\
              MemorySize: 10000000000
            Windows.Network.PacketCapture:
              Duration: 300
              Interface: 0
              
  memory_analysis:
    volatility:
      commands:
        - pslist: \"List running processes\"
        - connections: \"Show network connections\"
        - malfind: \"Find injected code\"
        - handles: \"List open handles\"
        - dlllist: \"List loaded DLLs\"
      script: |
        #!/bin/bash
        # Volatility analysis script
        MEMORY_DUMP=$1
        OUTPUT_DIR=$2
        
        # Determine profile
        vol.py -f $MEMORY_DUMP imageinfo > $OUTPUT_DIR/imageinfo.txt
        PROFILE=$(grep \"Suggested Profile\" $OUTPUT_DIR/imageinfo.txt | awk '{print $4}')
        
        # Run analysis commands
        vol.py -f $MEMORY_DUMP --profile=$PROFILE pslist > $OUTPUT_DIR/pslist.txt
        vol.py -f $MEMORY_DUMP --profile=$PROFILE connections > $OUTPUT_DIR/connections.txt
        vol.py -f $MEMORY_DUMP --profile=$PROFILE malfind > $OUTPUT_DIR/malfind.txt
        
  network_forensics:
    wireshark:
      capture_filter: \"host {infected_ip} and not host {forensics_server}\"
      analysis_commands:
        - \"tshark -r capture.pcap -Y 'http.request' -T fields -e ip.src -e http.host\"
        - \"tshark -r capture.pcap -Y 'dns' -T fields -e ip.src -e dns.name\"
        - \"tshark -r capture.pcap -Y 'ssl.handshake' -T fields -e ip.dst -e ssl.handshake.extension.server_name\"
```

## Automation and Orchestration

### SOAR Platform Integration
```python
from typing import Dict, List, Optional
import asyncio
import aiohttp
from datetime import datetime
import json

class ContainmentOrchestrator:
    def __init__(self, config_path: str):
        self.config = self.load_config(config_path)
        self.playbooks = {}
        self.active_incidents = {}
        self.containment_metrics = {}
        
    def load_config(self, config_path: str) -> Dict:
        \"\"\"Load orchestration configuration\"\"\"
        with open(config_path, 'r') as f:
            return json.load(f)
            
    async def execute_playbook(self, incident_id: str, playbook_name: str):
        \"\"\"Execute containment playbook\"\"\"
        playbook = self.playbooks.get(playbook_name)
        if not playbook:
            raise ValueError(f\"Playbook {playbook_name} not found\")
            
        incident_context = {
            'incident_id': incident_id,
            'playbook': playbook_name,
            'start_time': datetime.now(),
            'threat_indicators': await self.gather_threat_intel(incident_id),
            'affected_systems': await self.identify_affected_systems(incident_id)
        }
        
        # Execute playbook steps
        for step in playbook['steps']:
            try:
                result = await self.execute_step(step, incident_context)
                self.containment_metrics[incident_id]['steps_completed'].append({
                    'step': step['name'],
                    'status': 'success',
                    'result': result,
                    'timestamp': datetime.now()
                })
            except Exception as e:
                self.containment_metrics[incident_id]['steps_failed'].append({
                    'step': step['name'],
                    'status': 'failed',
                    'error': str(e),
                    'timestamp': datetime.now()
                })
                
                if step.get('critical', False):
                    raise
                    
        return self.containment_metrics[incident_id]
    
    async def gather_threat_intel(self, incident_id: str) -> Dict:
        """Gather threat intelligence for incident"""
        # Integrate with threat intel platforms
        threat_data = {
            'iocs': await self.extract_iocs(incident_id),
            'ttps': await self.identify_ttps(incident_id),
            'attribution': await self.attempt_attribution(incident_id)
        }
        return threat_data
        
    async def execute_step(self, step: Dict, context: Dict) -> Dict:
        """Execute individual playbook step"""
        step_type = step['type']
        
        if step_type == 'isolate_endpoint':
            return await self.isolate_endpoint(step['parameters'], context)
        elif step_type == 'block_network':
            return await self.block_network_traffic(step['parameters'], context)
        elif step_type == 'disable_account':
            return await self.disable_user_account(step['parameters'], context)
        elif step_type == 'collect_forensics':
            return await self.collect_forensic_data(step['parameters'], context)
        else:
            raise ValueError(f"Unknown step type: {step_type}")
    
    async def isolate_endpoint(self, params: Dict, context: Dict) -> Dict:
        """Isolate endpoint via EDR"""
        endpoint_id = params['endpoint_id']
        isolation_type = params.get('isolation_type', 'full')
        
        # Call EDR API
        async with aiohttp.ClientSession() as session:
            headers = {'Authorization': f'Bearer {self.config["edr_token"]}'}
            data = {
                'endpoint_id': endpoint_id,
                'isolation_type': isolation_type,
                'incident_id': context['incident_id']
            }
            
            async with session.post(
                f"{self.config['edr_api_url']}/isolate",
                headers=headers,
                json=data
            ) as response:
                return await response.json()
    
    async def block_network_traffic(self, params: Dict, context: Dict) -> Dict:
        """Block network traffic via firewall"""
        # Implementation for network blocking
        firewall_rules = params['rules']
        
        results = []
        for rule in firewall_rules:
            result = await self.apply_firewall_rule(rule)
            results.append(result)
            
        return {'rules_applied': len(results), 'results': results}
    
    async def monitor_containment(self, incident_id: str):
        """Monitor containment effectiveness"""
        while incident_id in self.active_incidents:
            metrics = await self.collect_containment_metrics(incident_id)
            
            # Check if containment is effective
            if metrics['new_infections'] == 0 and metrics['lateral_movement'] == False:
                self.containment_metrics[incident_id]['status'] = 'effective'
            else:
                self.containment_metrics[incident_id]['status'] = 'partial'
                
            # Update dashboard
            await self.update_dashboard(incident_id, metrics)
            
            # Wait before next check
            await asyncio.sleep(60)  # Check every minute

### Automated Response Workflows
```yaml
automated_workflows:
  ransomware_response:
    trigger_conditions:
      - file_encryption_detected: true
      - ransom_note_found: true
      - confidence_score: "> 90%"
    
    immediate_actions:
      - isolate_affected_systems:
          method: "edr_api"
          isolation_type: "full"
          preserve_forensics: true
      
      - disable_file_shares:
          scope: "affected_segments"
          method: "powershell_remote"
          
      - backup_preservation:
          action: "mark_readonly"
          notify: "backup_team"
    
    containment_expansion:
      - scan_lateral_movement:
          tools: ["siem", "edr", "network_flow"]
          time_window: "24_hours"
          
      - identify_patient_zero:
          correlation: "multi_source"
          priority: "high"
          
      - expand_isolation:
          criteria: "risk_based"
          approval: "automated"
    
  apt_response:
    trigger_conditions:
      - persistence_mechanism: "detected"
      - c2_communication: "confirmed"
      - data_staging: "observed"
    
    immediate_actions:
      - stealth_monitoring:
          duration: "configurable"
          goal: "identify_full_scope"
          
      - selective_containment:
          method: "surgical"
          preserve: "attacker_unaware"
          
      - deception_deployment:
          honeypots: "auto_deploy"
          fake_data: "generate"

### Integration Points
```python
class IntegrationManager:
    def __init__(self):
        self.integrations = {
            'edr': EDRIntegration(),
            'siem': SIEMIntegration(),
            'firewall': FirewallIntegration(),
            'identity': IdentityIntegration(),
            'ticketing': TicketingIntegration()
        }
        
    async def coordinate_response(self, incident: Dict):
        """Coordinate response across all platforms"""
        
        # Create incident ticket
        ticket = await self.integrations['ticketing'].create_incident(
            title=f"Malware Incident - {incident['id']}",
            priority=incident['severity'],
            description=incident['description']
        )
        
        # Gather data from all sources
        edr_data = await self.integrations['edr'].get_alerts(incident['timeframe'])
        siem_data = await self.integrations['siem'].query_events(incident['iocs'])
        
        # Execute containment across platforms
        tasks = []
        
        # EDR actions
        for system in incident['affected_systems']:
            task = self.integrations['edr'].isolate_system(system['id'])
            tasks.append(task)
            
        # Firewall actions
        for rule in incident['firewall_rules']:
            task = self.integrations['firewall'].apply_rule(rule)
            tasks.append(task)
            
        # Identity actions
        for user in incident['compromised_users']:
            task = self.integrations['identity'].disable_account(user['id'])
            tasks.append(task)
            
        # Execute all actions in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Update ticket with results
        await self.integrations['ticketing'].update_incident(
            ticket_id=ticket['id'],
            update={
                'status': 'containment_executed',
                'results': results
            }
        )
        
        return {
            'ticket_id': ticket['id'],
            'actions_executed': len(tasks),
            'results': results
        }
```

## Post-Containment Actions

### Forensic Analysis
```yaml
forensic_workflow:
  evidence_collection:
    memory_acquisition:
      tools:
        - winpmem
        - memdump
        - volatility
      process:
        - Capture RAM before isolation
        - Create multiple copies
        - Hash verification
        - Chain of custody documentation
        
    disk_imaging:
      tools:
        - FTK Imager
        - dd/dcfldd
        - EnCase
      process:
        - Create bit-for-bit copy
        - Verify integrity (hash)
        - Document all actions
        - Secure storage
        
    network_captures:
      tools:
        - tcpdump
        - Wireshark
        - NetworkMiner
      focus_areas:
        - C2 communications
        - Data exfiltration
        - Lateral movement
        - Beacon patterns
        
  analysis_priorities:
    timeline_reconstruction:
      - Initial compromise time
      - Persistence establishment
      - Lateral movement progression
      - Data access/exfiltration
      - Command execution history
      
    malware_analysis:
      static_analysis:
        - File hashes (MD5, SHA256, SHA1)
        - PE analysis
        - String extraction
        - Packer identification
        
      dynamic_analysis:
        - Sandbox execution
        - API monitoring
        - Network behavior
        - Registry modifications
        - File system changes
        
    attribution_indicators:
      - Code similarities
      - Infrastructure patterns
      - TTP alignment
      - Language artifacts
      - Timestamp analysis
```

### Eradication Planning
```python
class EradicationPlanner:
    def __init__(self):
        self.eradication_steps = []
        self.verification_points = []
        self.rollback_plan = {}
        
    def create_eradication_plan(self, incident_data: Dict) -> Dict:
        """Create comprehensive eradication plan"""
        
        plan = {
            'incident_id': incident_data['id'],
            'malware_family': incident_data['malware_family'],
            'affected_systems': incident_data['affected_systems'],
            'eradication_steps': [],
            'verification_steps': [],
            'timeline': {}
        }
        
        # Determine eradication strategy based on malware type
        if incident_data['malware_type'] == 'ransomware':
            plan['eradication_steps'] = self.ransomware_eradication_steps()
        elif incident_data['malware_type'] == 'apt':
            plan['eradication_steps'] = self.apt_eradication_steps()
        elif incident_data['malware_type'] == 'commodity':
            plan['eradication_steps'] = self.commodity_malware_steps()
            
        # Add verification steps
        plan['verification_steps'] = self.create_verification_steps(
            incident_data['iocs']
        )
        
        # Create timeline
        plan['timeline'] = self.create_eradication_timeline(
            plan['eradication_steps'],
            incident_data['business_priority']
        )
        
        return plan
        
    def ransomware_eradication_steps(self) -> List[Dict]:
        """Eradication steps specific to ransomware"""
        return [
            {
                'step': 'Kill malicious processes',
                'tools': ['edr', 'powershell'],
                'script': '''
                    Get-Process | Where-Object {
                        $_.ProcessName -match "malicious_pattern"
                    } | Stop-Process -Force
                '''
            },
            {
                'step': 'Remove persistence mechanisms',
                'locations': [
                    'Registry Run keys',
                    'Scheduled tasks',
                    'Services',
                    'Startup folders'
                ],
                'script': '''
                    # Remove registry persistence
                    Remove-ItemProperty -Path "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Run" -Name "MaliciousEntry"
                    
                    # Remove scheduled tasks
                    schtasks /delete /tn "MaliciousTask" /f
                    
                    # Remove services
                    sc delete MaliciousService
                '''
            },
            {
                'step': 'Clean infected files',
                'method': 'restore_from_backup',
                'alternative': 'decrypt_if_possible',
                'validation': 'hash_verification'
            },
            {
                'step': 'Reset credentials',
                'scope': 'all_affected_accounts',
                'include': [
                    'Local accounts',
                    'Domain accounts',
                    'Service accounts',
                    'Application credentials'
                ]
            }
        ]
        
    def create_verification_steps(self, iocs: List[Dict]) -> List[Dict]:
        """Create verification steps based on IOCs"""
        verification_steps = []
        
        for ioc in iocs:
            if ioc['type'] == 'file_hash':
                verification_steps.append({
                    'type': 'file_scan',
                    'method': 'hash_search',
                    'value': ioc['value'],
                    'expected_result': 'not_found'
                })
            elif ioc['type'] == 'registry_key':
                verification_steps.append({
                    'type': 'registry_check',
                    'path': ioc['path'],
                    'expected_result': 'not_exists'
                })
            elif ioc['type'] == 'network_connection':
                verification_steps.append({
                    'type': 'netstat_check',
                    'address': ioc['address'],
                    'port': ioc['port'],
                    'expected_result': 'no_connection'
                })
                
        return verification_steps
```

### Recovery Procedures
```yaml
recovery_procedures:
  system_restoration:
    pre_restoration_checks:
      - Verify malware eradication
      - Confirm clean backups
      - Test recovery procedures
      - Document current state
      
    restoration_order:
      1_critical_infrastructure:
        - Domain controllers
        - DNS servers
        - DHCP servers
        - Certificate authorities
        
      2_security_systems:
        - Firewall rules
        - IDS/IPS configurations
        - EDR agents
        - SIEM collectors
        
      3_business_services:
        - Email servers
        - File servers
        - Application servers
        - Database servers
        
      4_user_systems:
        - VIP workstations
        - Standard workstations
        - Mobile devices
        - Remote access
        
    validation_steps:
      functionality_testing:
        - Service availability
        - Performance benchmarks
        - User access verification
        - Application testing
        
      security_validation:
        - Patch levels current
        - Security tools operational
        - Configurations hardened
        - Monitoring active
        
  data_recovery:
    backup_validation:
      check_points:
        - Backup integrity
        - Recovery point objective
        - Malware-free verification
        - Test restoration
        
    recovery_methods:
      clean_backup_restore:
        - Identify last clean backup
        - Verify backup integrity
        - Restore to isolated system
        - Validate data integrity
        
      encrypted_file_recovery:
        - Attempt decryption tools
        - Shadow copy restoration
        - File carving techniques
        - Third-party recovery
        
    post_recovery_validation:
      - Data integrity checks
      - Application functionality
      - User acceptance testing
      - Performance validation
```

## Metrics and KPIs

### Containment Metrics
```yaml
containment_metrics:
  time_based_metrics:
    mean_time_to_detect:
      definition: "Time from infection to detection"
      formula: "detection_time - infection_time"
      target: "< 1 hour"
      
    mean_time_to_contain:
      definition: "Time from detection to containment"
      formula: "containment_time - detection_time"
      target: "< 2 hours"
      
    total_incident_duration:
      definition: "Time from detection to full recovery"
      formula: "recovery_time - detection_time"
      target: "< 24 hours"
      
  effectiveness_metrics:
    containment_effectiveness:
      definition: "Percentage of infected systems successfully contained"
      formula: "(contained_systems / infected_systems) * 100"
      target: "> 95%"
      
    lateral_movement_prevention:
      definition: "Systems infected after initial containment"
      formula: "post_containment_infections"
      target: "0"
      
    data_loss_prevention:
      definition: "Amount of data exfiltrated"
      formula: "data_exfiltrated_gb"
      target: "0 GB"
      
  business_impact_metrics:
    system_availability:
      definition: "Uptime during incident"
      formula: "(uptime_hours / total_hours) * 100"
      target: "> 99%"
      
    user_productivity_impact:
      definition: "Users affected by containment"
      formula: "affected_users / total_users * 100"
      target: "< 5%"
      
    financial_impact:
      components:
        - Downtime costs
        - Recovery costs
        - Reputation damage
        - Regulatory fines
      target: "Minimize"
      
  quality_metrics:
    false_positive_rate:
      definition: "Incorrectly contained systems"
      formula: "false_positives / total_containments * 100"
      target: "< 1%"
      
    automation_success_rate:
      definition: "Automated actions completed successfully"
      formula: "successful_automations / total_automations * 100"
      target: "> 98%"
      
    documentation_completeness:
      definition: "Incident documentation quality"
      components:
        - Timeline accuracy
        - Action logging
        - Evidence preservation
        - Lessons learned
      target: "100%"
```

### Performance Dashboard
```python
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import json

class ContainmentMetricsDashboard:
    def __init__(self):
        self.metrics_data = []
        self.kpi_targets = self.load_kpi_targets()
        
    def load_kpi_targets(self) -> Dict:
        """Load KPI targets from configuration"""
        return {
            'mttr': 120,  # Minutes
            'containment_rate': 95,  # Percentage
            'false_positive_rate': 1,  # Percentage
            'automation_success': 98  # Percentage
        }
        
    def calculate_metrics(self, incident_data: List[Dict]) -> pd.DataFrame:
        """Calculate containment metrics from incident data"""
        
        metrics = []
        for incident in incident_data:
            metric = {
                'incident_id': incident['id'],
                'detection_time': incident['detection_time'],
                'containment_time': incident['containment_time'],
                'recovery_time': incident['recovery_time'],
                'systems_affected': incident['systems_affected'],
                'systems_contained': incident['systems_contained'],
                'data_exfiltrated': incident.get('data_exfiltrated', 0),
                'false_positives': incident.get('false_positives', 0)
            }
            
            # Calculate derived metrics
            metric['time_to_contain'] = (
                metric['containment_time'] - metric['detection_time']
            ).total_seconds() / 60  # Minutes
            
            metric['containment_rate'] = (
                metric['systems_contained'] / metric['systems_affected'] * 100
            )
            
            metric['false_positive_rate'] = (
                metric['false_positives'] / metric['systems_contained'] * 100
                if metric['systems_contained'] > 0 else 0
            )
            
            metrics.append(metric)
            
        return pd.DataFrame(metrics)
        
    def generate_dashboard(self, metrics_df: pd.DataFrame):
        """Generate visual dashboard"""
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # Time to Contain Trend
        ax1.plot(metrics_df['detection_time'], metrics_df['time_to_contain'])
        ax1.axhline(y=self.kpi_targets['mttr'], color='r', linestyle='--')
        ax1.set_title('Time to Contain Trend')
        ax1.set_ylabel('Minutes')
        
        # Containment Rate
        ax2.bar(range(len(metrics_df)), metrics_df['containment_rate'])
        ax2.axhline(y=self.kpi_targets['containment_rate'], color='r', linestyle='--')
        ax2.set_title('Containment Effectiveness')
        ax2.set_ylabel('Percentage')
        
        # False Positive Rate
        ax3.scatter(metrics_df['detection_time'], metrics_df['false_positive_rate'])
        ax3.axhline(y=self.kpi_targets['false_positive_rate'], color='r', linestyle='--')
        ax3.set_title('False Positive Rate')
        ax3.set_ylabel('Percentage')
        
        # Systems Affected Over Time
        ax4.plot(metrics_df['detection_time'], metrics_df['systems_affected'])
        ax4.set_title('Systems Affected Over Time')
        ax4.set_ylabel('Count')
        
        plt.tight_layout()
        return fig
        
    def generate_executive_summary(self, metrics_df: pd.DataFrame) -> Dict:
        """Generate executive summary of metrics"""
        
        summary = {
            'period': {
                'start': metrics_df['detection_time'].min(),
                'end': metrics_df['detection_time'].max()
            },
            'incidents': {
                'total': len(metrics_df),
                'critical': len(metrics_df[metrics_df['systems_affected'] > 10]),
                'contained_successfully': len(
                    metrics_df[metrics_df['containment_rate'] >= self.kpi_targets['containment_rate']]
                )
            },
            'performance': {
                'avg_time_to_contain': metrics_df['time_to_contain'].mean(),
                'avg_containment_rate': metrics_df['containment_rate'].mean(),
                'total_systems_affected': metrics_df['systems_affected'].sum(),
                'total_data_loss_gb': metrics_df['data_exfiltrated'].sum()
            },
            'trends': {
                'improving_metrics': [],
                'degrading_metrics': [],
                'stable_metrics': []
            }
        }
        
        # Analyze trends
        if len(metrics_df) > 5:
            recent = metrics_df.tail(5)
            older = metrics_df.head(5)
            
            if recent['time_to_contain'].mean() < older['time_to_contain'].mean():
                summary['trends']['improving_metrics'].append('Time to Contain')
            else:
                summary['trends']['degrading_metrics'].append('Time to Contain')
                
        return summary
```

## Lessons Learned

### Post-Incident Review Process
```yaml
post_incident_review:
  review_timeline:
    immediate_debrief:
      timing: "Within 24 hours"
      participants:
        - Incident commander
        - Technical lead
        - Key responders
      focus:
        - What worked well
        - What failed
        - Immediate improvements
        
    detailed_analysis:
      timing: "Within 1 week"
      participants:
        - Full response team
        - Security leadership
        - Business stakeholders
      agenda:
        - Timeline reconstruction
        - Decision analysis
        - Tool effectiveness
        - Communication review
        
    strategic_review:
      timing: "Within 1 month"
      participants:
        - Executive team
        - Security leadership
        - Risk management
      topics:
        - Business impact
        - Cost analysis
        - Strategic improvements
        - Investment needs
        
  documentation_requirements:
    incident_report:
      sections:
        - Executive summary
        - Technical timeline
        - Root cause analysis
        - Containment effectiveness
        - Lessons learned
        - Recommendations
        
    evidence_archive:
      contents:
        - Forensic images
        - Network captures
        - Log files
        - Malware samples
        - Chain of custody
        
    knowledge_base_update:
      items:
        - New IOCs
        - TTP documentation
        - Playbook updates
        - Tool configurations
        - Training materials
```

### Continuous Improvement
```python
class ContinuousImprovement:
    def __init__(self):
        self.lessons_learned = []
        self.improvements_implemented = []
        self.metrics_baseline = {}
        
    def analyze_incident(self, incident_data: Dict) -> List[Dict]:
        """Analyze incident for improvement opportunities"""
        
        lessons = []
        
        # Analyze detection gaps
        if incident_data['time_to_detect'] > self.metrics_baseline['avg_detection_time']:
            lessons.append({
                'category': 'detection',
                'finding': 'Detection time exceeded baseline',
                'recommendation': 'Review detection rules and add new indicators',
                'priority': 'high'
            })
            
        # Analyze containment effectiveness
        if incident_data['containment_failures']:
            for failure in incident_data['containment_failures']:
                lessons.append({
                    'category': 'containment',
                    'finding': f"Containment failed: {failure['reason']}",
                    'recommendation': failure['suggested_fix'],
                    'priority': 'critical'
                })
                
        # Analyze tool performance
        for tool, metrics in incident_data['tool_performance'].items():
            if metrics['success_rate'] < 95:
                lessons.append({
                    'category': 'tools',
                    'finding': f"{tool} success rate below threshold",
                    'recommendation': f"Investigate {tool} failures and update configuration",
                    'priority': 'medium'
                })
                
        return lessons
        
    def track_improvements(self, improvement: Dict) -> None:
        """Track implementation of improvements"""
        
        improvement_record = {
            'id': str(uuid.uuid4()),
            'description': improvement['description'],
            'category': improvement['category'],
            'status': 'planned',
            'created_date': datetime.now(),
            'target_date': improvement['target_date'],
            'metrics_impact': improvement.get('expected_impact', {})
        }
        
        self.improvements_implemented.append(improvement_record)
        
    def measure_impact(self, improvement_id: str, current_metrics: Dict) -> Dict:
        """Measure impact of implemented improvements"""
        
        improvement = next(
            (imp for imp in self.improvements_implemented if imp['id'] == improvement_id),
            None
        )
        
        if not improvement:
            return {'error': 'Improvement not found'}
            
        impact_analysis = {
            'improvement_id': improvement_id,
            'implementation_date': improvement.get('completed_date'),
            'metrics_change': {}
        }
        
        # Compare current metrics with baseline
        for metric, current_value in current_metrics.items():
            if metric in self.metrics_baseline:
                baseline_value = self.metrics_baseline[metric]
                change_percent = ((current_value - baseline_value) / baseline_value) * 100
                
                impact_analysis['metrics_change'][metric] = {
                    'baseline': baseline_value,
                    'current': current_value,
                    'change_percent': change_percent,
                    'improved': change_percent < 0 if metric.endswith('time') else change_percent > 0
                }
                
        return impact_analysis
        
    def generate_improvement_roadmap(self, lessons: List[Dict]) -> Dict:
        """Generate improvement roadmap from lessons learned"""
        
        roadmap = {
            'short_term': [],  # 0-30 days
            'medium_term': [],  # 31-90 days
            'long_term': []  # 90+ days
        }
        
        for lesson in lessons:
            improvement = {
                'title': lesson['finding'],
                'description': lesson['recommendation'],
                'category': lesson['category'],
                'priority': lesson['priority'],
                'estimated_effort': self.estimate_effort(lesson),
                'dependencies': self.identify_dependencies(lesson)
            }
            
            # Categorize by timeline based on priority and effort
            if lesson['priority'] == 'critical' or improvement['estimated_effort'] == 'low':
                roadmap['short_term'].append(improvement)
            elif lesson['priority'] == 'high' or improvement['estimated_effort'] == 'medium':
                roadmap['medium_term'].append(improvement)
            else:
                roadmap['long_term'].append(improvement)
                
        return roadmap
```

### Training and Preparedness
```yaml
training_program:
  skill_development:
    technical_skills:
      malware_analysis:
        topics:
          - Static analysis techniques
          - Dynamic analysis methods
          - Reverse engineering basics
          - Sandbox usage
        format: "Hands-on labs"
        frequency: "Quarterly"
        
      forensics:
        topics:
          - Memory analysis
          - Disk forensics
          - Network forensics
          - Mobile forensics
        format: "Practical exercises"
        frequency: "Bi-annually"
        
      incident_response:
        topics:
          - MITRE ATT&CK framework
          - Threat hunting
          - Tool proficiency
          - Communication skills
        format: "Scenario-based training"
        frequency: "Monthly"
        
    soft_skills:
      crisis_management:
        - Decision making under pressure
        - Stakeholder communication
        - Team coordination
        - Stress management
        
      documentation:
        - Report writing
        - Evidence handling
        - Chain of custody
        - Legal considerations
        
  simulation_exercises:
    tabletop_exercises:
      frequency: "Monthly"
      scenarios:
        - Ransomware outbreak
        - APT detection
        - Insider threat
        - Supply chain attack
      participants:
        - Security team
        - IT operations
        - Management
        - Legal/Compliance
        
    purple_team_exercises:
      frequency: "Quarterly"
      objectives:
        - Test detection capabilities
        - Validate containment procedures
        - Practice coordination
        - Identify gaps
      metrics:
        - Detection time
        - Containment effectiveness
        - Communication quality
        - Decision accuracy
        
    full_scale_simulations:
      frequency: "Annually"
      scope:
        - Company-wide involvement
        - External stakeholders
        - Media simulation
        - Regulatory notification
      evaluation:
        - Response times
        - Decision quality
        - Communication effectiveness
        - Recovery success
        
  knowledge_sharing:
    internal_mechanisms:
      brown_bags:
        - Recent incidents
        - New threats
        - Tool updates
        - Best practices
        
      wiki_documentation:
        - Playbooks
        - Tool guides
        - Lessons learned
        - Contact lists
        
      mentorship_program:
        - Pair junior/senior
        - Rotation schedule
        - Skill assessment
        - Progress tracking
        
    external_engagement:
      conference_participation:
        - Industry conferences
        - Training courses
        - Certifications
        - Workshops
        
      information_sharing:
        - ISACs
        - Threat intel groups
        - Vendor communities
        - Research collaboration
```

## Appendices

### A. Tool Configuration Examples
```yaml
tool_configurations:
  edr_configurations:
    microsoft_defender:
      isolation_policies:
        full_isolation:
          network: "blocked"
          usb: "blocked"
          exceptions: ["security_tools"]
          
        selective_isolation:
          network: "restricted"
          allowed_ports: [22, 3389]
          allowed_ips: ["10.0.1.0/24"]
          
      detection_rules:
        ransomware_behavior:
          - mass_file_encryption
          - volume_shadow_deletion
          - backup_catalog_deletion
          
    crowdstrike:
      response_policies:
        critical_threat:
          actions:
            - isolate_host
            - kill_process
            - delete_file
            - collect_forensics
            
        suspicious_activity:
          actions:
            - monitor_enhanced
            - collect_telemetry
            - notify_soc
            
  siem_queries:
    splunk:
      lateral_movement_detection: |
        index=windows EventCode=4624 Logon_Type=3
        | stats count by src_ip, dest_host
        | where count > 5
        
      data_exfiltration: |
        index=firewall action=allowed
        | stats sum(bytes_out) as total_bytes by src_ip, dest_ip
        | where total_bytes > 1000000000
        
    sentinel_kql:
      ransomware_detection: |
        SecurityEvent
        | where EventID == 4688
        | where Process contains_any ("vssadmin", "wbadmin", "bcdedit")
        | summarize count() by Computer, Process
        
  firewall_rules:
    emergency_containment:
      inbound:
        - action: "deny"
          source: "any"
          destination: "infected_subnet"
          port: "any"
          protocol: "any"
          
      outbound:
        - action: "deny"
          source: "infected_subnet"
          destination: "any"
          port: "any"
          protocol: "any"
          exceptions:
            - destination: "security_tools"
              port: 443
              protocol: "tcp"
```

### B. Incident Response Checklist
```markdown
## Malware Containment Checklist

### Immediate Actions (0-15 minutes)
- [ ] Confirm malware detection
- [ ] Assess initial scope
- [ ] Notify incident commander
- [ ] Begin evidence preservation
- [ ] Implement initial containment

### Early Response (15-60 minutes)
- [ ] Activate response team
- [ ] Isolate affected systems
- [ ] Collect volatile data
- [ ] Block malicious indicators
- [ ] Begin impact assessment

### Containment Expansion (1-4 hours)
- [ ] Identify all affected systems
- [ ] Implement network segmentation
- [ ] Disable compromised accounts
- [ ] Update security tools
- [ ] Coordinate with stakeholders

### Stabilization (4-24 hours)
- [ ] Verify containment effectiveness
- [ ] Complete forensic collection
- [ ] Plan eradication strategy
- [ ] Prepare recovery plan
- [ ] Update executive management

### Recovery Planning (24+ hours)
- [ ] Develop eradication plan
- [ ] Test recovery procedures
- [ ] Schedule maintenance windows
- [ ] Prepare user communications
- [ ] Document lessons learned
```

### C. Contact Lists and Escalation
```yaml
escalation_matrix:
  internal_contacts:
    level_1_soc:
      on_call: "+1-xxx-xxx-xxxx"
      email: "soc@company.com"
      escalation_time: "15 minutes"
      
    level_2_senior_analyst:
      primary: "+1-xxx-xxx-xxxx"
      backup: "+1-xxx-xxx-xxxx"
      email: "senior-soc@company.com"
      escalation_time: "30 minutes"
      
    level_3_management:
      ciso: "+1-xxx-xxx-xxxx"
      security_director: "+1-xxx-xxx-xxxx"
      email: "security-leadership@company.com"
      escalation_time: "1 hour"
      
  external_contacts:
    incident_response_firm:
      primary: "Vendor IR Team"
      hotline: "+1-800-xxx-xxxx"
      email: "ir@vendor.com"
      contract: "#12345"
      
    law_enforcement:
      fbi_cyber: "+1-xxx-xxx-xxxx"
      local_pd: "+1-xxx-xxx-xxxx"
      evidence_requirements: "Chain of custody required"
      
    cyber_insurance:
      carrier: "Insurance Company"
      policy: "#CYB-67890"
      hotline: "+1-800-xxx-xxxx"
      claim_email: "claims@insurer.com"
      
  notification_requirements:
    regulatory:
      gdpr:
        timeline: "72 hours"
        authority: "Local DPA"
        threshold: "Personal data breach"
        
      state_breach:
        timeline: "Without unreasonable delay"
        authority: "State AG"
        threshold: "PII exposure"
        
    contractual:
      customers:
        timeline: "Per contract"
        method: "Secure portal"
        content: "Approved template"
        
      partners:
        timeline: "24 hours"
        method: "Encrypted email"
        approval: "Legal required"
```

This comprehensive malware containment documentation provides detailed procedures, scripts, configurations, and guidance for effectively containing malware incidents while minimizing business impact and preserving evidence for investigation.
`